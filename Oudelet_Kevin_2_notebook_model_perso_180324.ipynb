{"cells":[{"attachments":{},"cell_type":"markdown","id":"c10447d1","metadata":{"id":"c10447d1"},"source":["## **Classez des images**\n","\n","### partie 2/4 : modèle perso\n","\n","<br>\n","\n","> #### notebook de mise en oeuvre de création et d’entraînement du modèle personnel, des simulations des différentes valeurs des hyperparamètres et de data augmentation.. <br><br>\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["## 0 Imports\n"]},{"attachments":{},"cell_type":"markdown","id":"8cf10133","metadata":{"id":"8cf10133"},"source":["### 0.1 Librairies, réglages\n"]},{"cell_type":"code","execution_count":null,"id":"6ffe8b0d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9566,"status":"ok","timestamp":1688504146442,"user":{"displayName":"Kevin Oudelet","userId":"05301463766297982835"},"user_tz":-120},"id":"6ffe8b0d","outputId":"4abc7d5f-4fe6-46db-fa59-05891e583e93"},"outputs":[],"source":["# paths, folders/files\n","import os, sys, random, re\n","from os import listdir\n","from glob import glob\n","from zipfile import ZipFile\n","import time\n","\n","# math, dataframes\n","import numpy as np\n","import pandas as pd\n","from pandarallel import pandarallel\n","from collections import Counter\n","\n","# Visualisation\n","from pprint import pprint\n","import matplotlib.pyplot as plt\n","from matplotlib.image import imread\n","import seaborn as sns\n","import plotly.express as px\n","# from wordcloud import WordCloud\n","# from PIL import Image\n","\n","# Feature engineering\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import preprocessing\n","from sklearn import manifold, decomposition\n","from sklearn import cluster, metrics\n","from sklearn.model_selection import train_test_split\n","# from sklearn.feature_extraction.text import CountVectorizer\n","\n","# NN\n","import tensorflow as tf\n","from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","print('\\nPython version ' + sys.version)\n","print('Tensorflow version ' + tf.__version__)\n","print('Keras version ' + tf.keras.__version__)\n","\n","# plt.style.use('ggplot')\n","pd.set_option('display.max_columns', 200)\n","\n","# Modify if necessary\n","num_cores = os.cpu_count()\n","print(f\"\\nNumber of CPU cores: {num_cores}\")\n","pandarallel.initialize(progress_bar=False, nb_workers=6)\n"]},{"cell_type":"markdown","id":"6dc1e6dd","metadata":{},"source":["### 0.2 Fonctions\n"]},{"cell_type":"code","execution_count":null,"id":"6370e828","metadata":{},"outputs":[],"source":["model_results = []\n","\n","def affichage_results():\n","    \"\"\"Tracking manuel de nos modèles (data, params, tps, scores) pour comparaison.\"\"\"\n","\n","    # Create a DataFrame from the list of model results\n","    model_comparison_df = pd.concat([pd.DataFrame(model_results)], ignore_index=True)\n","\n","    # Sort the DataFrame by precision in descending order (higher is better)\n","    model_comparison_df.sort_values(by='accuracy_val_moy', ascending=False, inplace=True)\n","\n","    # Display the sorted DataFrame\n","    display(model_comparison_df)\n"]},{"cell_type":"markdown","id":"93756304","metadata":{},"source":["### 0.3 Variables globales\n"]},{"cell_type":"code","execution_count":null,"id":"47c701d2","metadata":{},"outputs":[],"source":["nb_classes = 3      # min 2, max 120\n","\n","size_wh = 128\n","target_size=(size_wh, size_wh) # pour grille 5x5, stride (2,2) ?\n","\n","alea = 42 # pour fixer les ttsplits et tjs travailler sur les mm datasets\n","# En revanche l'initialisation des poids des modèles restera aléatoire,\n","# pour pouvoir comparer les resultats sur +ieurs runs.\n","\n","epochs = 10\n"]},{"cell_type":"markdown","id":"00274e86","metadata":{},"source":["### 0.4 Metriques\n"]},{"cell_type":"code","execution_count":null,"id":"66c82819","metadata":{},"outputs":[],"source":["# J'utiliserai tjs les noms anglais des métriques ici,\n","# pour éviter la confusion précision (fr) != precision (en),\n","# et pour simplement garder les noms des fonctions importées depuis tf.keras.metrics\n","\n","# Nous sommes dans un cas de classification \"classique\", 1 classe prédite.\n","# Une première métrique simple et intuitive est donc l'accuracy :\n","# nb de prédictions correctes / nb total de prédictions.\n","# Cette métrique nous suffit déjà pour comparer et optimiser nos modèles.\n","\n","# Si l'on souhaite étudier + en détail les prédictions des modèles, on utilisera\n","# la precison et le recall\n","\n","# Precison (TP / (TP + FP)) :\n","# Une précision élevée signifie que si une classe est prédite par le modèle,\n","# alors il y a une forte probabilité (égale à la precision)\n","# que le chien appartienne en effet à cette classe.\n","\n","# Recall (TP / (TP + FN)) :\n","# pour évaluer la capacité des modèles à identifier toutes les instances positives.\n","# Exemple : Si notre precision est égale à 1, c'est parfais, cela signifie que\n","# pour une une classe au moins, toutes les valeurs prédites par le modèle sont correctes.\n","# Cependant, il est possible que cela ne concerne que très peu de cas (mettons, 1 ou 2 prédictions)\n","# et qu'à côté de cela le modèle a pu faire des milliers de prédictions incorrectes,\n","# la precision seule ne nous le dit pas.\n","\n","# Comme l'amélioration de la precision se fait svt au détriment du recall, en pratique\n","# on combine souvent les 2 avec le f1score (= moyenne harmonique)\n","# (2 x precision x recall) / (precision + recall)\n","# qui nous donne directement une idée du compromis precision / recall\n","\n","# petit souci : le f1score et keras, c'est tout une histoire...\n","# Dans les versions récentes (depuis la 2.15.0 il me semble), le f1score est directement intégré\n","# au module metrics. Le problème est que conda n'arrive pas à résoudre un env avec ces versions,\n","# incompatibles avec les requirements d'autres packages dans l'env.\n","\n","# Dans les versions + anciennes de keras, le f1score était dans un autre module, \"addons\",\n","# mais ce moule est désormais déprécié.\n","# Solution : on va juste faire un f1score custom ?\n","# ??\n","\n","def f1score(y_true, y_pred):\n","    precision = Precision(y_true, y_pred)\n","    recall = Recall(y_true, y_pred)\n","    f1 = (2*precision*recall) / (precision + recall)\n","\n","    return f1\n","\n","\n","metrics=[\n","    'Accuracy',\n","    # f1score,\n","    # AUC(),\n","]\n"]},{"cell_type":"markdown","metadata":{},"source":["### 0.4 Data\n"]},{"cell_type":"code","execution_count":null,"id":"ed6a46d8","metadata":{},"outputs":[],"source":["data = pd.read_csv('./data/data_3_classes.csv', sep=',')\n","\n","print(data.shape)\n","data.head()\n"]},{"attachments":{},"cell_type":"markdown","id":"a334fc5e","metadata":{"id":"a334fc5e"},"source":["### 0.5 Etude de faisabilité (sort of)\n"]},{"cell_type":"code","execution_count":null,"id":"00ea9423","metadata":{},"outputs":[],"source":["# Ici l'étude de faisabilité préconisée par la méthode Agile n'est pas vraiment utile en tant que telle\n","# (On sait que le projet est faisable). Il s'agit plutôt de pouvoir observer le travail effectué par le\n","# bloc d'encodage, sans utiliser d'algorithme de prediction supervisée\n","# (algo classique ou plutôt, ici, bloc des layers fully connected)\n","\n","images_features = []\n","\n","for image_file in data[\"photo_path\"] :\n","    image = load_img(image_file, target_size=(180, 180))\n","    image = img_to_array(image)\n","    images_features.append(image)\n","\n","images_features = np.asarray(images_features)\n","images_features.shape\n"]},{"cell_type":"code","execution_count":null,"id":"7dafe1cd","metadata":{},"outputs":[],"source":["# Reshape images to flatten them into vectors\n","flattened_images = images_features.reshape(images_features.shape[0], -1)\n","print(flattened_images.shape)\n","\n","# Normalize the data\n","scaler = StandardScaler()\n","normalized_images = scaler.fit_transform(flattened_images)\n"]},{"cell_type":"markdown","id":"e5331844","metadata":{},"source":["### 0.6 Réduction dim\n"]},{"cell_type":"code","execution_count":null,"id":"155e6954","metadata":{},"outputs":[],"source":["# PCA\n","\n","print(normalized_images.shape) # same as flattened_images\n","\n","pca = decomposition.PCA(n_components=0.99)\n","feat_pca= pca.fit_transform(normalized_images)\n","\n","print(feat_pca.shape)\n","\n","# dimention divisée par 200 (presque), en conservant 99% de la variance !\n"]},{"cell_type":"code","execution_count":null,"id":"1a7bed7c","metadata":{},"outputs":[],"source":["# Plot explained variance ratio\n","plt.figure(figsize=(8, 6))\n","plt.plot(range(1, pca.n_components_ + 1), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--', color='#3af')\n","plt.xlabel('Number of Principal Components')\n","plt.ylabel('Cumulative Explained Variance Ratio')\n","plt.title('Cumulative Explained Variance Ratio vs. Number of Principal Components')\n","plt.grid(True)\n","plt.show()\n","\n","# Pourquoi on a besoin du tsne pour la visu : en 2D ou même en 3D, les 3 premiers vecteurs propres\n","# # fournis par la PCA ne captent \"que\" (environ) un tiers de l'information.\n","# Ce qu'on verrait serait très déformé par les projections successives de la PCA.\n","# tester ?\n"]},{"cell_type":"markdown","id":"1790650e","metadata":{},"source":["### 0.7 tsne\n"]},{"cell_type":"code","execution_count":null,"id":"01528ec8","metadata":{},"outputs":[],"source":["# t-sne\n","\n","tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, init='random', random_state=6)\n","X_tsne = tsne.fit_transform(feat_pca)\n"]},{"cell_type":"code","execution_count":null,"id":"010e972c","metadata":{},"outputs":[],"source":["# encodage target\n","\n","label_encoder = preprocessing.LabelEncoder()\n","label_encoder.fit(data[\"breed\"])\n","\n","data[\"target\"] = label_encoder.transform(data[\"breed\"])\n","\n","display(data.head(1))\n","data.tail(1)\n"]},{"cell_type":"code","execution_count":null,"id":"e794502e","metadata":{},"outputs":[],"source":["df_tsne = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n","df_tsne[\"class\"] = data[\"target\"]\n","\n","plt.figure(figsize=(8,5))\n","sns.scatterplot(\n","    x=\"tsne1\", y=\"tsne2\",\n","    hue=\"class\",\n","    palette=sns.color_palette('tab10', n_colors=3), s=50, alpha=0.6,\n","    data=df_tsne,\n","    legend=\"brief\")\n","\n","plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n","plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n","plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n","plt.legend(prop={'size': 14})\n","\n","plt.show()\n","\n","# Ca marche moins bien sans extraction de features !\n","# On retentera en fin de notebook, en utilisant notre modèle.\n"]},{"cell_type":"markdown","id":"5fbfb928","metadata":{},"source":["### 1 Création d'un premier modèle\n"]},{"cell_type":"code","execution_count":null,"id":"b0d17859","metadata":{},"outputs":[],"source":["# Notre objectifs principal ici est\n","# de pouvoir observer / comprendre la fonction des différentes layers utilisées.\n","\n","# Pour cela, nous allons commencer par une architecture très simple :\n","# le but n'est pas d'avoir le modèle le + performant possible.\n","# (irréaliste ici car on n'aurait ni le tps ni les ressources pour l'entrainer)\n","# (en revanche, voir le notebook 3, transfer learning, pour une comparaison de modèles + complexes)\n","\n","# Première idée :\n","# Notre modèle de base sera donc inspiré d'AlexNet, dont l'architecture est :\n","\n","# \"AlexNet contains eight layers: the first five are convolutional layers,\n","# some of them followed by max-pooling layers, and the last three are fully connected layers.\n","# [...] The entire structure can be written as:\n","\n","# (CNN -> RN -> MP)^2 -> (CNN^3 -> MP) -> (FC -> DO)^2 -> Linear -> softmax\n","\n","# where\n","# CNN = convolutional layer (with ReLU activation)\n","# RN = local response normalization\n","# MP = maxpooling\n","# FC = fully connected layer (with ReLU activation)\n","# Linear = fully connected layer (without activation)\n","# DO = dropout\n","\n","# It used the non-saturating ReLU activation function, which showed improved training performance\n","# over tanh and sigmoid.\" (wiki)\n"]},{"cell_type":"markdown","id":"dcaab114","metadata":{},"source":["### 1.1 LeNet inspired architecture\n"]},{"cell_type":"code","execution_count":null,"id":"c72ad8b8","metadata":{},"outputs":[],"source":["# Problème : 8 groupes de layers... (16 individuelles, en fait) C'est déjà beaucoup !\n","# On peut faire + simple, au moins pour commencer.\n","\n","# Voyons de quoi sera capable un modèle inspiré plutôt par LeNet-5\n","# et par ce notebook : https://www.kaggle.com/code/schmoyote/simple-cnn-architecture-for-image-classification/notebook\n","\n","model = Sequential()\n","model.add(Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(size_wh, size_wh, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","# model.add(Dense(120, activation='tanh'))\n","model.add(Dense(60, activation='tanh'))\n","model.add(Dense(nb_classes, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n","\n","model.summary()\n"]},{"cell_type":"markdown","id":"91f12626","metadata":{},"source":["### 1.2 feature engineering\n"]},{"cell_type":"code","execution_count":null,"id":"1ebe7531","metadata":{},"outputs":[],"source":["feature = \"photo_path\"\n","\n","X_feature = []\n","\n","for image_file in data[feature] :\n","    image = load_img(image_file, target_size=target_size)\n","    image = img_to_array(image)\n","    X_feature.append(image)\n","\n","X_feature = np.asarray(X_feature)\n","\n","print(\"Shape of X_train:\", X_feature.shape)\n","# ok\n"]},{"cell_type":"markdown","id":"6a22a0d0","metadata":{},"source":["### 1.3 label encoding target\n"]},{"cell_type":"code","execution_count":null,"id":"1b8fa580","metadata":{},"outputs":[],"source":["y_target = np.asarray(data[\"target\"])\n","print(y_target.shape)\n","pprint(y_target)\n"]},{"cell_type":"code","execution_count":null,"id":"6511ff83","metadata":{},"outputs":[],"source":["# delete ? move ?\n","\n","# Ici une simple normalisation de la valeur des pixels\n","# + transfo en tensor pour tf\n","\n","def load_and_normalize(img_address):\n","    image = load_img(img_address, target_size=(180, 180)) # redondant (target_size)\n","    image = img_to_array(image)\n","    # image = tf.convert_to_tensor(image)\n","    return image\n","\n","\n","# data['input'] = data['denoised'].apply(load_and_normalize)\n","\n","# data.head(1)\n"]},{"cell_type":"markdown","id":"02f5b733","metadata":{},"source":["### 1.4 train test split\n"]},{"cell_type":"code","execution_count":null,"id":"560656c8","metadata":{},"outputs":[],"source":["X_train_val, X_test, y_train_val, y_test = train_test_split(X_feature, y_target, test_size=0.1,\n","                                                            shuffle=True, random_state=alea,\n","                                                            stratify=y_target) # important\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1,\n","                                                            shuffle=True, random_state=alea,\n","                                                            stratify=y_train_val)\n","\n","print(X_train.shape)\n","print(X_val.shape)\n","print(X_test.shape, '\\n')\n","\n","print(y_train.shape)\n","print(y_val.shape)\n","print(y_test.shape, '\\n')\n"]},{"cell_type":"markdown","id":"a1d114a8","metadata":{},"source":["### 1.5 one hot encoding (targets)\n"]},{"cell_type":"code","execution_count":null,"id":"1ee0d23f","metadata":{},"outputs":[],"source":["# One-hot encode target values after the split to avoid data leakage\n","\n","y_train_ohe = tf.keras.utils.to_categorical(y_train)\n","y_val_ohe = tf.keras.utils.to_categorical(y_val)\n","y_test_ohe = tf.keras.utils.to_categorical(y_test)\n"]},{"cell_type":"markdown","id":"b49e2120","metadata":{},"source":["### 1.6 Training\n"]},{"cell_type":"code","execution_count":null,"id":"05cbd2f5","metadata":{},"outputs":[],"source":["# Train the model\n","model.fit(X_train, y_train_ohe, epochs=epochs, batch_size=32,\n","          validation_data=(X_val, y_val_ohe))\n"]},{"cell_type":"markdown","id":"5f18e540","metadata":{},"source":["### 1.7 Evaluation\n"]},{"cell_type":"code","execution_count":null,"id":"ccf7cf32","metadata":{},"outputs":[],"source":["# On overfit dès le début ??\n","\n","# Evaluate the model\n","val_loss_ref, val_acc_ref = model.evaluate(X_val, y_val_ohe)\n","print('Val accuracy:', val_acc_ref)\n","\n","# En prédisant au hasard on aurait une chance sur 3, autrement dit\n","# ce modèle fait des prédictions quasi-aléatoires.\n","# Pas terrible, mais c'est un début !\n","\n","# avant, tester sur photos d'origine (pour évaluer l'utilité du prétraitement effectué)\n"]},{"cell_type":"code","execution_count":null,"id":"c7e3160d","metadata":{},"outputs":[],"source":["# petit tracking manuel\n","results = {'model': 'V1',\n","            'df': 'data_3_classes',\n","            'feature': feature,\n","            'accuracy_val_moy': val_acc_ref,\n","            'time_fit': 'to do',\n","            'time_predict':'to do'\n","            }\n","\n","# Append a new row for this model\n","model_results.append(results)\n"]},{"cell_type":"markdown","id":"6d8286ee","metadata":{},"source":["### 1.8 test utilité prétraitements\n"]},{"cell_type":"code","execution_count":null,"id":"b8b78821","metadata":{},"outputs":[],"source":["def test_feature(df=data, feature='photo_path', epochs=epochs):  # photos d'origine, jpg, redim (<=> 'resized')\n","\n","    # feature, target\n","    X_feature = []\n","\n","    for image_file in df[feature]:\n","        image = load_img(image_file, target_size=target_size)\n","        image = img_to_array(image)\n","        X_feature.append(image)\n","\n","    X_feature = np.asarray(X_feature)\n","\n","    y_target = np.asarray(data[\"target\"])\n","\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(X_feature, y_target, test_size=0.1,\n","                                                                shuffle=True, random_state=alea,\n","                                                                stratify=y_target) # important\n","\n","    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1,\n","                                                                shuffle=True, random_state=alea,\n","                                                                stratify=y_train_val)\n","\n","    y_train_ohe = tf.keras.utils.to_categorical(y_train)\n","    y_val_ohe = tf.keras.utils.to_categorical(y_val)\n","    y_test_ohe = tf.keras.utils.to_categorical(y_test)\n","\n","    # model\n","    model = Sequential()\n","    model.add(Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(size_wh, size_wh, 3)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    # model.add(Dense(120, activation='tanh'))\n","    model.add(Dense(60, activation='tanh'))\n","    model.add(Dense(nb_classes, activation='softmax'))\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n","\n","    model.fit(X_train, y_train_ohe, epochs=epochs, batch_size=32,\n","            validation_data=(X_val, y_val_ohe))\n","\n","    _, val_acc = model.evaluate(X_val, y_val_ohe)\n","    print(f'Val accuracy (feature={feature}): {val_acc}')\n","\n","    results = {'model': 'V1',\n","            'df': 'data_3_classes',\n","            'feature': feature,\n","            'accuracy_val_moy': val_acc,\n","            'time_fit': 'to do',\n","            'time_predict':'to do'\n","            }\n","\n","    # Append a new row for this model\n","    model_results.append(results)\n","\n","\n","test_feature(df=data, feature='resized')\n","\n","# rappel\n","print(f'Test accuracy (photo_path original): {val_acc_ref}')\n","\n","\n","# 0.6 de precision sans pretraitement (parfois 0.3 ??), 0.3 avec.\n","# Notre prétraitement semble (très) contre-productif. Ajuster dim, filtres ? (trop flou ?)\n","# Comme prétraitement, les méthodes .preprocessing() de keras consistent svt seulement en\n","# redimensionnemt + normalisation.\n","# faire pareil ?\n"]},{"cell_type":"code","execution_count":null,"id":"20a2dc28","metadata":{},"outputs":[],"source":["#\n","\n","features_to_test = ['expo', 'contraste', 'denoised']\n","\n","for feature in features_to_test:\n","    print(feature)\n","    test_feature(df=data, feature=feature)\n","\n","\n","# results\n","# 'resized' 0.32 ???\n","# 'expo' 0.63\n","# 'contraste' 0.32\n"]},{"cell_type":"markdown","id":"6e3ee68f","metadata":{},"source":["### Comparaison\n"]},{"cell_type":"code","execution_count":null,"id":"9d78a24b","metadata":{},"outputs":[],"source":["affichage_results()\n","\n","# On y voit déjà (un peu) + clair :\n","# Chaque étape de notre prétraitement semble + ou - détériorer la qualité des prédictions.\n","\n","# Encore que... ?\n","# ??? resized et photo_path devraient donner des résultats bien + proches, non ??\n","# sets identiques sauf dim, et redim lors de création de X_feature\n","# ... devraient être exactement identiques, et donc avoir des resultats proches\n","\n","# En fait d'un run à l'autre, les prédictions varient énormément...\n","# difficile du coup d'évaluer l'impact de nos prétraitements.\n","# moyenne sur +ieurs runs ?\n","\n","model_results = []\n","\n","# Svt le modèle ne parvient pas à \"train ses layers\", et l'accuracy des prédictions\n","# sur le jeu de validation reste au niveau de prédictions random.\n"]},{"cell_type":"markdown","id":"ca35c058","metadata":{},"source":["### Mean multiple runs\n"]},{"cell_type":"code","execution_count":null,"id":"69a97743","metadata":{},"outputs":[],"source":["# mlflow ?\n","\n","nb_runs = 10\n","\n","\n","def test_feature_n_times(df=data, feature='photo_path', epochs=epochs, n=nb_runs):\n","    \"\"\"\n","\n","    \"\"\"\n","    results_val_acc, results_time_fit,  results_time_predict = [], [], []\n","\n","    for i in range(n):\n","\n","        print(f'\\nRun {i}\\n')\n","\n","        # feature, target\n","        X_feature = []\n","\n","        for image_file in df[feature]:\n","            image = load_img(image_file, target_size=target_size)\n","            image = img_to_array(image)\n","            X_feature.append(image)\n","\n","        X_feature = np.asarray(X_feature)\n","\n","        y_target = np.asarray(data[\"target\"])\n","\n","        X_train_val, X_test, y_train_val, y_test = train_test_split(X_feature, y_target, test_size=0.1,\n","                                                                    shuffle=True, random_state=alea,\n","                                                                    stratify=y_target) # important\n","\n","        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1,\n","                                                                    shuffle=True, random_state=alea,\n","                                                                    stratify=y_train_val)\n","\n","        y_train_ohe = tf.keras.utils.to_categorical(y_train)\n","        y_val_ohe = tf.keras.utils.to_categorical(y_val)\n","        y_test_ohe = tf.keras.utils.to_categorical(y_test)\n","\n","        # model\n","        model = Sequential()\n","        model.add(Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(size_wh, size_wh, 3)))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Flatten())\n","        # model.add(Dense(120, activation='tanh'))\n","        model.add(Dense(60, activation='tanh'))\n","        model.add(Dense(nb_classes, activation='softmax'))\n","\n","        # Compile the model\n","        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","        # fit model and time it\n","        time_fit_start = time.time()\n","        model.fit(X_train, y_train_ohe, epochs=epochs, batch_size=32,\n","                validation_data=(X_val, y_val_ohe))\n","        time_fit_end = time.time()\n","        time_fit = time_fit_start - time_fit_end\n","\n","        # time predictions\n","        time_predict_start = time.time()\n","        _, val_acc = model.evaluate(X_val, y_val_ohe)\n","        time_predict_end = time.time()\n","        time_predict = time_predict_start - time_predict_end\n","\n","        print(f'Test accuracy (feature={feature}): {val_acc}')\n","\n","        results_val_acc.append(val_acc)\n","        results_time_fit.append(time_fit)\n","        results_time_predict.append(time_predict)\n","\n","    # moyennes\n","    mean_val_acc = np.mean(results_val_acc)\n","    mean_time_fit = np.mean(results_time_fit)\n","    mean_time_predict = np.mean(results_time_predict)\n","\n","    # écarts-types (utile ici pour le score, afin d'avoir une idée de la \"régularité\" des résultats)\n","    # les tps d'entrainement / prédiction st bcp + stables\n","    std_val_acc = np.std(results_val_acc)\n","\n","    results = {'model': 'V1',\n","        'df': 'data_3_classes',\n","        'feature': feature,\n","        'accuracy_val_moy': mean_val_acc,\n","        'accuracy_val_std': std_val_acc,\n","        'time_fit_moy': mean_time_fit,\n","        'time_predict_moy': mean_time_predict,\n","        }\n","\n","    # Append a new row for this model\n","    model_results.append(results)\n","\n","\n","test_feature_n_times()\n","\n","#\n"]},{"cell_type":"code","execution_count":null,"id":"3f3eb909","metadata":{},"outputs":[],"source":["test_feature_n_times(feature='resized')\n"]},{"cell_type":"code","execution_count":null,"id":"1dd552cb","metadata":{},"outputs":[],"source":["test_feature_n_times(feature='expo')\n"]},{"cell_type":"code","execution_count":null,"id":"44381692","metadata":{},"outputs":[],"source":["test_feature_n_times(feature='contraste')\n"]},{"cell_type":"code","execution_count":null,"id":"eb191dab","metadata":{},"outputs":[],"source":["test_feature_n_times(feature='denoised')\n"]},{"cell_type":"code","execution_count":null,"id":"accc094c","metadata":{},"outputs":[],"source":["affichage_results()\n","\n","# model_results = []\n","\n","# log / picle model. size ?\n"]},{"cell_type":"markdown","id":"fe001dc4","metadata":{},"source":["### Ameliorations\n"]},{"cell_type":"code","execution_count":null,"id":"87f62f99","metadata":{},"outputs":[],"source":["# 3 pistes d'améliorations possibles,\n","\n","# retour au preprocessing\n","# data augmentation\n","# model\n"]},{"cell_type":"code","execution_count":null,"id":"3753c0dc","metadata":{},"outputs":[],"source":["# Activation Functions: Tanh activation functions are commonly used in LeNet, but you might\n","# experiment with other activation functions like ReLU (Rectified Linear Unit), which tend to perform well\n","#  in many scenarios.\n","\n","# Optimizer: The Adam optimizer is a good choice, but you might also experiment with other optimizers\n","# such as RMSprop or SGD (Stochastic Gradient Descent) with momentum.\n","\n","# Loss Function: Cross-entropy loss is appropriate for classification tasks with softmax activation\n","# in the output layer, so categorical_crossentropy is fine.\n","\n","# Model Capacity: LeNet is a relatively shallow network compared to modern architectures.\n","# Depending on the complexity of your dataset, you might need to adjust the model's capacity\n","# by adding more convolutional layers or increasing the number of units in the fully connected layers.\n","\n","# Regularization: You may consider adding regularization techniques such as dropout or weight decay\n","# to prevent overfitting, especially if you observe overfitting during training.\n","\n","# smaller grids ?\n","# modify input shape ?\n","\n","# inception module + global average pooling ?\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
